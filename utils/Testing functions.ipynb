{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cdd455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import OpenAI\n",
    "from dotenv import dotenv_values\n",
    "from IPython.display import Image, display\n",
    "from googlesearch import search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddd51396",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")\n",
    "client = OpenAI(api_key=config[\"APIKEY\"])\n",
    "\n",
    "def icelandic_to_english(product_name):\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4o\",\n",
    "        temperature = 0.8,\n",
    "        messages = [\n",
    "            {\"role\":\"system\",\"content\":\"You are a translator who translates the Product name from Icelandic to English and just provide the translated product name and nothing else.\"},\n",
    "            {\"role\":\"user\",\"content\":product_name}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1ba2835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_product_links_google(product_name, brand, sku, max_links=5):\n",
    "    print(f\"\\nðŸ” Searching for: {product_name} | {brand} | {sku}\")\n",
    "    query = f\"{product_name} {brand} {sku} site:*.com\"\n",
    "    print(\"ðŸ”Ž Query:\", query)\n",
    "\n",
    "    raw_links = []\n",
    "    try:\n",
    "        for result in search(query, num_results=15):\n",
    "            if result.startswith(\"http\") and \"/search?\" not in result:\n",
    "                raw_links.append(result)\n",
    "    except Exception as e:\n",
    "        print(\"âŒ Google search failed:\", e)\n",
    "        return []\n",
    "\n",
    "    print(\"ðŸŒ Fetched Links:\")\n",
    "    for link in raw_links:\n",
    "        print(\"  -\", link)\n",
    "\n",
    "    # âœ… Keep only typical product detail pages\n",
    "    allowed_patterns = re.compile(r\"(product|products|detail|dp|sku|/p/|/item/|/shop/)\", re.IGNORECASE)\n",
    "\n",
    "    filtered_links = []\n",
    "    for url in raw_links:\n",
    "        if not allowed_patterns.search(url):\n",
    "            continue\n",
    "        try:\n",
    "            r = requests.get(url, timeout=8)\n",
    "            if r.status_code == 200 and (\n",
    "                sku.lower() in r.text.lower()\n",
    "                or brand.lower() in r.text.lower()\n",
    "                or product_name.split()[0].lower() in r.text.lower()\n",
    "            ):\n",
    "                filtered_links.append(url)\n",
    "            if len(filtered_links) >= max_links:\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return filtered_links\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15124e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_urls(links, global_limit=20):\n",
    "    print(\"\\nðŸ–¼ï¸ Extracting images from source URLs...\")\n",
    "    image_urls = []\n",
    "    allowed_ext = (\".jpg\", \".jpeg\", \".png\", \".webp\")\n",
    "    blocked_terms = [\"sprite\", \"icon\", \"logo\", \"tracking\", \"facebook\", \"pixel\", \"blank\"]\n",
    "\n",
    "    for url in links:\n",
    "        try:\n",
    "            res = requests.get(url, timeout=10)\n",
    "            if res.status_code != 200:\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(res.text, 'html.parser')\n",
    "            imgs = soup.find_all('img')\n",
    "\n",
    "            for tag in imgs:\n",
    "                src = tag.get('src') or tag.get('data-src') or tag.get('data-original')\n",
    "                if not src:\n",
    "                    continue\n",
    "                src = src.strip()\n",
    "                if src.startswith('//'):\n",
    "                    src = 'https:' + src\n",
    "                if not src.startswith('http'):\n",
    "                    continue\n",
    "                if not src.lower().endswith(allowed_ext):\n",
    "                    continue\n",
    "                if any(blocked in src.lower() for blocked in blocked_terms):\n",
    "                    continue\n",
    "\n",
    "                image_urls.append(src)\n",
    "                if len(image_urls) >= global_limit:\n",
    "                    break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        if len(image_urls) >= global_limit:\n",
    "            break\n",
    "\n",
    "    return image_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcf796bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Searching for: Samsung Microwave 23 Liter | Samsung | SAM-MS23K3513ASEE\n",
      "ðŸ”Ž Query: Samsung Microwave 23 Liter Samsung SAM-MS23K3513ASEE site:*.com\n",
      "ðŸŒ Fetched Links:\n",
      "\n",
      "ðŸ–¼ï¸ Extracting images from source URLs...\n",
      "\n",
      "âœ… Final Image URLs:\n"
     ]
    }
   ],
   "source": [
    "product_name = \"Samsung Ã–rbylgjuofn 23 lÃ­tra\"\n",
    "brand = \"Samsung\"\n",
    "sku = \"SAM-MS23K3513ASEE\"\n",
    "\n",
    "# Translate\n",
    "product_name_en = icelandic_to_english(product_name)\n",
    "\n",
    "# Get valid product links\n",
    "valid_links = search_product_links_google(product_name_en, brand, sku, max_links=5)\n",
    "\n",
    "# Get image URLs\n",
    "image_urls = extract_images_from_urls(valid_links, global_limit=10)\n",
    "\n",
    "print(\"\\nâœ… Final Image URLs:\")\n",
    "for url in image_urls:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daba9e29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ–¼ï¸ Displaying Images:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ–¼ï¸ Displaying Images:\")\n",
    "for url in image_urls:\n",
    "    try:\n",
    "        display(Image(url=url, width=250))\n",
    "    except Exception:\n",
    "        print(f\"âš ï¸ Failed to load image: {url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0270b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6171bded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade81388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7df99b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "import re\n",
    "import requests\n",
    "\n",
    "def search_product_links_google(product_name, brand, sku, max_links=5):\n",
    "    print(f\"\\nðŸ” Searching for: {product_name}, {sku}\")\n",
    "    query = f\"{product_name} {brand} {sku} site:*.com\"\n",
    "    print(\"ðŸ”Ž Query:\", query)\n",
    "\n",
    "    raw_links = []\n",
    "    try:\n",
    "        for result in search(query, num_results=15):\n",
    "            if result.startswith(\"http\") and \"/search?\" not in result:\n",
    "                raw_links.append(result)\n",
    "    except Exception as e:\n",
    "        print(\"âŒ Google search failed:\", e)\n",
    "        return []\n",
    "\n",
    "    print(\"ðŸŒ Fetched Links:\")\n",
    "    for link in raw_links:\n",
    "        print(\"  -\", link)\n",
    "\n",
    "    # âœ… Keep only typical product detail pages\n",
    "    allowed_patterns = re.compile(r\"(product|products|detail|dp|sku|/p/|/item/|/shop/)\", re.IGNORECASE)\n",
    "\n",
    "    filtered_links = []\n",
    "    for url in raw_links:\n",
    "#         if not allowed_patterns.search(url):\n",
    "#             continue\n",
    "        try:\n",
    "            r = requests.get(url, timeout=8)\n",
    "            if r.status_code == 200 and (\n",
    "                sku.lower() in r.text.lower()\n",
    "                or brand.lower() in r.text.lower()\n",
    "                or product_name.split()[0].lower() in r.text.lower()\n",
    "            ):\n",
    "                filtered_links.append(url)\n",
    "            if len(filtered_links) >= max_links:\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return filtered_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec6c1e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Searching for: Samsung Microwave Oven 23 Liters, SAM-MS23K3513ASEE\n",
      "ðŸ”Ž Query: Samsung Microwave Oven 23 Liters Samsung SAM-MS23K3513ASEE site:*.com\n",
      "ðŸŒ Fetched Links:\n",
      "\n",
      "âœ… Final Valid Product Links:\n"
     ]
    }
   ],
   "source": [
    "product_name = \"Samsung Ã–rbylgjuofn 23 lÃ­tra\"\n",
    "brand = \"Samsung\"\n",
    "sku = \"SAM-MS23K3513ASEE\"\n",
    "\n",
    "product_name_en = icelandic_to_english(product_name)  # If needed, or use product_name directly\n",
    "\n",
    "valid_links = search_product_links_google(product_name_en, brand, sku, max_links=5)\n",
    "\n",
    "print(\"\\nâœ… Final Valid Product Links:\")\n",
    "for link in valid_links:\n",
    "    print(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef265089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "\n",
    "def search_product_links_google(product_name, brand, sku, max_links=5):\n",
    "    query = f\"{product_name} {sku} site:*.com\"\n",
    "    print(f\"\\nðŸ” Searching for: hello, {brand}, {sku}\")\n",
    "    print(\"ðŸŒ Query:\", query)\n",
    "\n",
    "    raw_links = []\n",
    "    try:\n",
    "        for result in search(query, num_results=15):\n",
    "            if result.startswith(\"http\") and \"/search?\" not in result:\n",
    "                raw_links.append(result)\n",
    "    except Exception as e:\n",
    "        print(\"âŒ Google search failed:\", e)\n",
    "        return []\n",
    "\n",
    "    print(\"\\nðŸŒ Fetched Links:\")\n",
    "    for link in raw_links:\n",
    "        print(\"  -\", link)\n",
    "\n",
    "    return raw_links[:max_links]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "08f9696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Searching for: hello, Samsung, SAM-MS23K3513ASEE\n",
      "ðŸŒ Query: Samsung Microwave Oven 23 Liters SAM-MS23K3513ASEE site:*.com\n",
      "âŒ Google search failed: 429 Client Error: Too Many Requests for url: https://www.google.com/sorry/index?continue=https://www.google.com/search%3Fq%3DSamsung%2BMicrowave%2BOven%2B23%2BLiters%2BSAM-MS23K3513ASEE%2Bsite%253A%252A.com%26num%3D17%26hl%3Den%26start%3D0%26safe%3Dactive&hl=en&q=EgQ88xJ7GMyFxcIGIjDaXqGb9eKf7gvjIPk2-f0G1Uaq0w3gL4hGTr4GXunmA0nMAbAFQj_RuxPxmvMCq2QyAnJSWgFD\n"
     ]
    }
   ],
   "source": [
    "product_name = \"Samsung Microwave Oven 23 Liters\"\n",
    "brand = \"Samsung\"\n",
    "sku = \"SAM-MS23K3513ASEE\"\n",
    "\n",
    "links = search_product_links_google(product_name, brand, sku)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaeb71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4afa7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb583e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4eabc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5faa9cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "992a904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def fetch_google_links(product_name, sku, num_results=3):\n",
    "    query = f\"{product_name} {sku}\"\n",
    "    encoded_query = quote(query)\n",
    "    url = f\"https://www.google.com/search?q={encoded_query}\"\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/114.0.0.0 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"âŒ Failed to fetch: HTTP {response.status_code}\")\n",
    "            return []\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        links = []\n",
    "        \n",
    "        for a in soup.select(\"a\"):\n",
    "            href = a.get(\"href\", \"\")\n",
    "            if href.startswith(\"/url?q=\") and \"webcache\" not in href:\n",
    "                real_link = href.split(\"/url?q=\")[1].split(\"&\")[0]\n",
    "                links.append(real_link)\n",
    "                if len(links) == num_results:\n",
    "                    break\n",
    "        \n",
    "        return links\n",
    "    except Exception as e:\n",
    "        print(\"âŒ Exception occurred:\", e)\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b593f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Product Name: Samsung Microwave Oven 23 Liters\n",
      "Enter Product SKU: SAM-MS23K3513ASEE\n",
      "âŒ Failed to fetch: HTTP 429\n",
      "\n",
      "ðŸ”— Top Google Search Results:\n"
     ]
    }
   ],
   "source": [
    "product = input(\"Enter Product Name: \")\n",
    "sku = input(\"Enter Product SKU: \")\n",
    "\n",
    "top_links = fetch_google_links(product, sku)\n",
    "\n",
    "print(\"\\nðŸ”— Top Google Search Results:\")\n",
    "for i, link in enumerate(top_links, 1):\n",
    "    print(f\"{i}. {link}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5790e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f81024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa49924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87c0f3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\gurur\\anaconda3\\lib\\site-packages (4.33.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\gurur\\anaconda3\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: urllib3[socks]~=2.4.0 in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from selenium) (2.4.0)\n",
      "Requirement already satisfied: trio~=0.30.0 in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.12.2 in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.4.26 in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from selenium) (2025.6.15)\n",
      "Requirement already satisfied: typing_extensions~=4.13.2 in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from selenium) (4.13.2)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from webdriver-manager) (23.1)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from urllib3[socks]~=2.4.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\gurur\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "00431142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from urllib.parse import quote\n",
    "import time\n",
    "\n",
    "def google_search_with_browser(product_name, sku, num_results=3):\n",
    "    query = f\"{product_name} {sku}\"\n",
    "    search_url = f\"https://www.google.com/search?q={quote(query)}\"\n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless=new\")  # Modern headless mode\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(search_url)\n",
    "        time.sleep(2)  # Allow JS to load content\n",
    "\n",
    "        print(\"ðŸ”Ž Page Title:\", driver.title)\n",
    "\n",
    "        # NEW: Locate all result blocks\n",
    "        containers = driver.find_elements(By.CSS_SELECTOR, \"div.MjjYud\")\n",
    "        top_links = []\n",
    "\n",
    "        for container in containers:\n",
    "            try:\n",
    "                link_tag = container.find_element(By.TAG_NAME, \"a\")\n",
    "                link = link_tag.get_attribute(\"href\")\n",
    "                if link and \"google.com/search\" not in link:\n",
    "                    top_links.append(link)\n",
    "                if len(top_links) == num_results:\n",
    "                    break\n",
    "            except:\n",
    "                continue  # If no link, skip\n",
    "\n",
    "        return top_links\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"âŒ Error:\", e)\n",
    "        return []\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "37d48c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Product Name: LG 100\" QNED UHD Smart TV\n",
      "Enter Product SKU: LG-100QNED86A6\n",
      "ðŸ”Ž Page Title: https://www.google.com/search?q=LG%20100%22%20QNED%20UHD%20Smart%20TV%20LG-100QNED86A6&sei=JEJRaLygLoGTseMP7JzEwAo\n",
      "\n",
      "ðŸ”— Top Google Search Results:\n"
     ]
    }
   ],
   "source": [
    "product = input(\"Enter Product Name: \")\n",
    "sku = input(\"Enter Product SKU: \")\n",
    "\n",
    "top_links = google_search_with_browser(product, sku)\n",
    "\n",
    "print(\"\\nðŸ”— Top Google Search Results:\")\n",
    "for i, link in enumerate(top_links, 1):\n",
    "    print(f\"{i}. {link}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba8aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49900812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3853e443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ad88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "933ab794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Google Results:\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "\n",
    "def google_search(query, num_results=3):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/114.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    # Construct Google Search URL\n",
    "    query_encoded = urllib.parse.quote_plus(query)\n",
    "    url = f\"https://www.google.com/search?q={query_encoded}&hl=en\"\n",
    "    \n",
    "    # Send GET request\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extract all search result links\n",
    "    links = []\n",
    "    for a_tag in soup.find_all(\"a\", href=True):\n",
    "        href = a_tag[\"href\"]\n",
    "        if href.startswith(\"/url?q=\"):\n",
    "            actual_url = href.split(\"/url?q=\")[1].split(\"&\")[0]\n",
    "            if \"google.com\" not in actual_url:\n",
    "                links.append(actual_url)\n",
    "        if len(links) >= num_results:\n",
    "            break\n",
    "    \n",
    "    return links\n",
    "\n",
    "# Example usage\n",
    "query = \"best Python IDEs 2025\"\n",
    "top_links = google_search(query)\n",
    "\n",
    "print(\"Top Google Results:\")\n",
    "for i, link in enumerate(top_links, 1):\n",
    "    print(f\"{i}. {link}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695614b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
